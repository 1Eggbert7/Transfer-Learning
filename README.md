# Transfer Learning for Pet Breed Classification

This project explores the use of **Transfer Learning** with **Convolutional Neural Networks (ConvNets)** and **Pseudo-Labeling**, a semi-supervised learning technique, for multi-class breed classification. The work fine-tunes a pre-trained ResNet-50 model on the **Oxford-IIIT Pet Dataset** to classify 37 different pet breeds.

## Authors
- Alexander Leszczynski - alexander.leszczynski@yahoo.de
- Jule Marie Schmidt
- Dominykas Jogela

## Abstract
The study incorporates transfer learning and pseudo-labeling to improve model performance in scenarios with limited labeled data. Key outcomes include:
- Achieved a classification accuracy of **92.07%**, surpassing the ResNet50 state-of-the-art benchmark.
- Demonstrated the potential of pseudo-labeling to leverage unlabeled data, increasing accuracy by up to **3%** in low-data scenarios.

## Dataset
The **Oxford-IIIT Pet Dataset** is used for training and testing:
- Contains 37 pet breeds with around 200 images per breed.
- Images vary in size, aspect ratio, and conditions (e.g., pose, lighting).

## Methodology
1. **Transfer Learning**: Fine-tuned ResNet-50, replacing and retraining its fully connected layers.
2. **Data Augmentation**: Applied transformations like horizontal flipping, random rotation, and cropping to enhance robustness.
3. **Gradual Unfreezing**: Strategically trained layers in phases, starting from the top layers and progressively including earlier layers.
4. **Pseudo-Labeling**: Leveraged unlabeled data with pseudo-labels generated by the model during training.

## Experiments
1. **Fine-Tuning**: Improved baseline accuracy of 87% to 92.07%.
2. **Less Data**: Demonstrated robust performance with reduced labeled data:
   - 50% labeled data: **88.8%**
   - 10% labeled data: **80.6%**
   - 1% labeled data: **40%**
3. **Pseudo-Labeling**:
   - Increased accuracy by 3.8% (using 10% labeled data and pseudo-labels).

## Key Results
| Percentage of Labeled Data | Accuracy (Baseline) | Accuracy (Pseudo-Labeling) |
|----------------------------|---------------------|----------------------------|
| 100%                       | 92.07%             | -                          |
| 50%                        | 88.8%              | 89.97%                     |
| 10%                        | 80.6%              | 84.4%                      |
| 1%                         | 40.0%              | 44.48%                     |

## Real-World Application
The model's robustness was validated with unseen data (images of my pet dog "Dora" not in the dataset). The classification results demonstrated its adaptability for practical scenarios.

## Conclusion
This project highlights:
- The effectiveness of transfer learning in achieving high accuracy with limited labeled data.
- The potential of pseudo-labeling to leverage unlabeled data for improved performance.
